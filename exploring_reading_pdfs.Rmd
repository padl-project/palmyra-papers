---
title: "Organizing PDF papers into Data frame"
author: "Camila Vargas"
date: "5/16/2022"
output: html_document
---

Exploring if it is possible to transform all text of a PDF paper into R to be able to do text analysis. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(pdftools)
library(revtools)
```


## Read pdf

```{r}
paper_path <- file.path("pdfs/wegmann_et_al_2019.pdf")

paper_raw <- pdf_text(paper_path)

## Returns a list with data for each pg. Identifies different columns
paper_data <- pdf_data(paper_path)

```

`pdf_text()` returns a vector of strings, one **for each page of the pdf**.  So we can mess with it in tidyverse style, let's turn it into a dataframe, and keep track of the pages.


## List to data frame

```{r}
## All 5 page
paper_df <- ldply (paper_data, data.frame)

## pg 2 for testing
df_pg2 <- data.frame(paper_data[2])

```


```{r}

df_test <- df_pg2 %>%
  mutate(x = round(x / 3),        #reduce resolution to minimise inconsistent coordinate
         y = round(y / 3)) %>%
  arrange(y, x) %>%                        #sort in reading order
  mutate(group = cumsum(!lag(space, default = 0))) %>%  #identify text with spaces and paste
  group_by(group) %>%
  summarise(x = first(x),
            y = first(y),
            text = paste(text, collapse = " ")) %>%
  group_by(y) %>%
  mutate(colno = row_number()) %>%         #add column numbers for table data
  ungroup() %>%
  select(text, colno, y) %>%
  pivot_wider(names_from = colno, values_from = text) %>% #pivot into table format
  select(-y) %>%
  set_names(c("car", .[1, -ncol(.)])) %>%   #shift names from first row
  slice(-1,-nrow(.)) %>%                  #remove names row and page number row
  mutate_at(-1, as.numeric)



```




We can use `stringr::str_split()` to break the pages up into individual lines.  Each line of the pdf is concluded with a backslash-n, so split on this.  We will also add a line number in addition to the page number.

```{r}

paper_df <- data.frame(text = paper_raw) %>%
  mutate(page = 1:n()) %>%
  mutate(text_sep = str_split(text, '\\n')) %>%
  unnest(text_sep)

smith_df <- data.frame(text = smith_text) %>%
  mutate(page = 1:n()) %>%
  mutate(text_sep = str_split(text, '\\n')) %>%
  unnest(text_sep) %>%
  group_by(page) %>%
  mutate(line = 1:n()) %>%
  ungroup()


```


```{r}
txt_output <- paper_raw %>%
  paste0(collapse = " ") %>%
  paste0(collapse = " ") %>%
  stringr::str_squish()
```




## Revtools to analyse pubs metadata

Useful to read .bib and .ris files but not useful for analysis.

```{r}
bib_test <- read_bibliography("data/export-data.bib")

ris_test <- read_bibliography("data/export-data.ris")

all_test <- bind_rows(bib_test, ris_test)

dupli <- find_duplicates(all_test, 
                         match_variable = "title",
                         to_lower = TRUE, 
                         remove_punctuation = TRUE)

data_unique <- extract_unique_references(all_test, dupli)

```





